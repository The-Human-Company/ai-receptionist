# Product-Specific Evaluation Criteria

Detailed evaluation frameworks for each NGM product type, designed to ensure comprehensive coverage during physician panel review.

---

## Report Generator Evaluation

### Core Dimensions

#### 1. Clinical Accuracy (Weight: 30%)

| Criterion | Questions | Scoring |
|-----------|-----------|---------|
| **Interpretation Correctness** | Are biomarker interpretations medically accurate? | 0-3 |
| **Reference Range Appropriateness** | Are optimal ranges used (not just lab ranges)? | 0-3 |
| **Context Sensitivity** | Do interpretations vary by age, sex, goals? | 0-3 |
| **Mechanism Explanation** | Does it explain WHY, not just what? | 0-3 |
| **Evidence Quality** | Are recommendations backed by current evidence? | 0-3 |

**Scoring Guide:**
- 0 = Incorrect or harmful
- 1 = Partially correct but significant gaps
- 2 = Mostly correct with minor issues
- 3 = Clinically accurate and thorough

#### 2. Actionability (Weight: 25%)

| Criterion | Questions | Scoring |
|-----------|-----------|---------|
| **Recommendation Specificity** | Are interventions specific and implementable? | 0-3 |
| **Prioritization** | Is it clear what to address first? | 0-3 |
| **Dosing Guidance** | Are doses provided with appropriate caveats? | 0-3 |
| **Follow-up Clarity** | Is it clear when to retest and what to monitor? | 0-3 |
| **Patient Handoff** | Can the patient understand their action items? | 0-3 |

#### 3. Personalization (Weight: 20%)

| Criterion | Questions | Scoring |
|-----------|-----------|---------|
| **Demographics** | Does it account for age, sex, ethnicity? | 0-3 |
| **Goals Alignment** | Does it consider patient goals (longevity vs. performance)? | 0-3 |
| **Historical Context** | Does it reference previous results if available? | 0-3 |
| **Comorbidity Awareness** | Does it flag relevant condition interactions? | 0-3 |
| **Medication Considerations** | Does it account for current medications? | 0-3 |

#### 4. Readability (Weight: 15%)

| Criterion | Questions | Scoring |
|-----------|-----------|---------|
| **Clinician Scannability** | Can a busy clinician get the key points in 30 seconds? | 0-3 |
| **Patient Accessibility** | Can patients understand the main findings? | 0-3 |
| **Visual Hierarchy** | Are important items visually emphasized? | 0-3 |
| **Organization** | Is information logically organized? | 0-3 |
| **Terminology Balance** | Medical accuracy without being inaccessible? | 0-3 |

#### 5. Safety & Liability (Weight: 10%)

| Criterion | Questions | Scoring |
|-----------|-----------|---------|
| **Medical Disclaimers** | Are appropriate disclaimers present? | 0-3 |
| **Red Flag Identification** | Are critical values properly flagged? | 0-3 |
| **Scope Boundaries** | Does it stay within appropriate clinical bounds? | 0-3 |
| **Referral Triggers** | Does it recommend specialist consults when needed? | 0-3 |
| **Contraindication Alerts** | Are dangerous interactions flagged? | 0-3 |

### Report-Specific Checks

**Metabolic Reports:**
- [ ] Glucose uses optimal range (75-85), not just lab range (70-100)
- [ ] Insulin resistance calculated and interpreted
- [ ] Metabolic age or trajectory assessment included
- [ ] Dietary and lifestyle recommendations specific

**Hormone Reports:**
- [ ] Sex-specific reference ranges used
- [ ] Circadian and cycling considerations noted
- [ ] Symptom correlation encouraged
- [ ] HRT options discussed when appropriate

**Inflammatory/Immune Reports:**
- [ ] Full inflammatory panel considered (hs-CRP, IL-6, TNF-alpha, etc.)
- [ ] Pattern recognition across markers
- [ ] Gut-immune connection addressed
- [ ] Chronic vs. acute inflammation distinguished

**Longevity Marker Reports:**
- [ ] Biological age estimates contextualized
- [ ] Modifiable vs. non-modifiable factors separated
- [ ] Rate of aging trajectory shown if historical data available
- [ ] Intervention prioritization based on impact

---

## Biomarker Analysis Tool Evaluation

### Core Dimensions

#### 1. Test Selection Logic (Weight: 30%)

| Criterion | Questions | Scoring |
|-----------|-----------|---------|
| **Clinical Relevance** | Are recommended tests clinically justified? | 0-3 |
| **Panel Coherence** | Do suggested panels make sense together? | 0-3 |
| **Goal Alignment** | Do tests match stated patient goals? | 0-3 |
| **Redundancy Avoidance** | Are overlapping tests minimized? | 0-3 |
| **Cost Consideration** | Is test cost factored into recommendations? | 0-3 |

#### 2. Interpretation Quality (Weight: 30%)

| Criterion | Questions | Scoring |
|-----------|-----------|---------|
| **Range Appropriateness** | Optimal vs. lab reference ranges used correctly? | 0-3 |
| **Context Application** | Age, sex, condition factors applied? | 0-3 |
| **Pattern Recognition** | Multi-marker patterns identified? | 0-3 |
| **Trend Analysis** | Historical trends factored in? | 0-3 |
| **Uncertainty Communication** | Limitations of tests acknowledged? | 0-3 |

#### 3. Practical Utility (Weight: 25%)

| Criterion | Questions | Scoring |
|-----------|-----------|---------|
| **Workflow Integration** | Does it fit clinical workflow? | 0-3 |
| **Order Generation** | Can it generate lab orders? | 0-3 |
| **Insurance Navigation** | Are coverage considerations included? | 0-3 |
| **Timing Guidance** | Is optimal testing timing provided? | 0-3 |
| **Follow-up Planning** | Are retest intervals suggested? | 0-3 |

#### 4. Novel Marker Coverage (Weight: 15%)

| Criterion | Questions | Scoring |
|-----------|-----------|---------|
| **Emerging Biomarkers** | Are newer longevity markers included? | 0-3 |
| **Evidence Level Clarity** | Is the evidence base for novel markers clear? | 0-3 |
| **Interpretation Guidance** | Are novel markers interpreted appropriately? | 0-3 |
| **Clinical Utility Honest** | Is clinical utility honestly assessed? | 0-3 |
| **Cost-Benefit Transparency** | Are expensive novel tests justified? | 0-3 |

### Biomarker-Specific Checks

**Must-Include Basic Panels:**
- [ ] Comprehensive metabolic panel with optimal ranges
- [ ] Complete lipid panel including ApoB, Lp(a)
- [ ] Inflammatory markers (hs-CRP minimum)
- [ ] Metabolic health markers (fasting insulin, HbA1c)
- [ ] Thyroid panel (TSH, Free T4, Free T3 minimum)

**Advanced Panels (When Appropriate):**
- [ ] Hormone panels (sex-specific, comprehensive)
- [ ] Nutrient status (B vitamins, D, minerals)
- [ ] Methylation markers (homocysteine, B12)
- [ ] Oxidative stress markers
- [ ] Genetic/epigenetic markers

---

## Chatbot/AI Output Evaluation

### Core Dimensions

#### 1. Medical Accuracy (Weight: 35%)

| Criterion | Questions | Scoring |
|-----------|-----------|---------|
| **Factual Correctness** | Is the information medically accurate? | 0-3 |
| **Current Evidence** | Does it reflect current (not outdated) science? | 0-3 |
| **Mechanism Accuracy** | Are mechanistic explanations correct? | 0-3 |
| **Dosing Correctness** | Are suggested doses accurate and safe? | 0-3 |
| **Interaction Awareness** | Are drug/supplement interactions flagged? | 0-3 |

#### 2. Safety & Appropriate Caveats (Weight: 30%)

| Criterion | Questions | Scoring |
|-----------|-----------|---------|
| **Physician Referral** | Does it recommend seeing a doctor when needed? | 0-3 |
| **Uncertainty Acknowledgment** | Does it acknowledge what we don't know? | 0-3 |
| **Individual Variation** | Does it note that responses vary? | 0-3 |
| **Contraindication Checking** | Does it ask about/flag contraindications? | 0-3 |
| **Scope Boundaries** | Does it stay within appropriate advisory limits? | 0-3 |

#### 3. Protocol Quality (Weight: 20%)

| Criterion | Questions | Scoring |
|-----------|-----------|---------|
| **Evidence Basis** | Are protocol suggestions evidence-based? | 0-3 |
| **Practical Implementability** | Can suggestions actually be implemented? | 0-3 |
| **Monitoring Guidance** | Are monitoring recommendations included? | 0-3 |
| **Adjustment Flexibility** | Does it account for needed adjustments? | 0-3 |
| **Duration Clarity** | Are treatment durations specified? | 0-3 |

#### 4. Communication Quality (Weight: 15%)

| Criterion | Questions | Scoring |
|-----------|-----------|---------|
| **Tone Appropriateness** | Professional but accessible? | 0-3 |
| **Source Attribution** | Are sources cited? | 0-3 |
| **Clarity** | Is the information clear and understandable? | 0-3 |
| **Completeness** | Does it fully answer the question? | 0-3 |
| **Conciseness** | Is it appropriately concise without gaps? | 0-3 |

### Chatbot-Specific Checks

**Safety Non-Negotiables:**
- [ ] Never provides specific medical diagnosis
- [ ] Always recommends physician involvement for significant decisions
- [ ] Flags emergency situations appropriately
- [ ] Acknowledges limitations of AI advice

**Quality Indicators:**
- [ ] Citations provided for key claims
- [ ] Doses include ranges and caveats, not single numbers
- [ ] Acknowledges individual variation
- [ ] Provides both conservative and advanced options where appropriate

---

## Vendor Directory/Intelligence Platform Evaluation

### Core Dimensions

#### 1. Objectivity & Fairness (Weight: 30%)

| Criterion | Questions | Scoring |
|-----------|-----------|---------|
| **Bias Freedom** | Is evaluation unbiased by sponsorship or relationships? | 0-3 |
| **Balanced Assessment** | Are both pros and cons covered? | 0-3 |
| **Evidence-Based Claims** | Are vendor claims verified or noted as unverified? | 0-3 |
| **Conflict Disclosure** | Are any financial relationships disclosed? | 0-3 |
| **Comparative Fairness** | Are similar vendors evaluated by same criteria? | 0-3 |

#### 2. Completeness (Weight: 25%)

| Criterion | Questions | Scoring |
|-----------|-----------|---------|
| **Product Coverage** | Are all major product categories covered? | 0-3 |
| **Feature Completeness** | Are key features thoroughly documented? | 0-3 |
| **Pricing Transparency** | Is pricing clearly and accurately stated? | 0-3 |
| **Integration Details** | Are technical integrations documented? | 0-3 |
| **Support Information** | Is customer support quality assessed? | 0-3 |

#### 3. Clinical Utility (Weight: 25%)

| Criterion | Questions | Scoring |
|-----------|-----------|---------|
| **Clinician Focus** | Is information relevant to clinical decision-making? | 0-3 |
| **Use Case Clarity** | Is it clear who this vendor is best for? | 0-3 |
| **Outcome Evidence** | Is there evidence of clinical outcomes? | 0-3 |
| **Workflow Impact** | Is impact on clinical workflow assessed? | 0-3 |
| **Comparison Enablement** | Can clinicians easily compare alternatives? | 0-3 |

#### 4. Currency & Reliability (Weight: 20%)

| Criterion | Questions | Scoring |
|-----------|-----------|---------|
| **Update Frequency** | How recently was information verified? | 0-3 |
| **Source Documentation** | Are information sources documented? | 0-3 |
| **Version Tracking** | Are product version changes tracked? | 0-3 |
| **Accuracy Verification** | Is there a process to verify accuracy? | 0-3 |
| **Feedback Integration** | Is clinician feedback incorporated? | 0-3 |

### Vendor Category-Specific Checks

**Lab/Testing Vendors:**
- [ ] Test menu completeness
- [ ] Reference range standards used
- [ ] Turnaround times
- [ ] Insurance coverage
- [ ] Sample requirements
- [ ] Quality certifications (CLIA, CAP)

**Supplement/Nutraceutical Vendors:**
- [ ] Third-party testing verification
- [ ] Ingredient sourcing transparency
- [ ] Formulation rationale
- [ ] Clinician pricing programs
- [ ] Dispensing platform integration

**Technology/Platform Vendors:**
- [ ] EHR integration capabilities
- [ ] Data security standards
- [ ] Feature comparison with alternatives
- [ ] Implementation requirements
- [ ] Ongoing support model

**Service Vendors:**
- [ ] Credentialing of providers
- [ ] Outcome data availability
- [ ] Geographic coverage
- [ ] Insurance/cash pay models
- [ ] Referral process

---

## Evaluation Scoring Summary

### Overall Score Calculation

```
Total Score = (Dimension1 × Weight1) + (Dimension2 × Weight2) + ...

Score Interpretation:
- 0.0-1.0: Critical issues, do not release
- 1.0-2.0: Significant issues, needs major work
- 2.0-2.5: Moderate issues, needs improvement
- 2.5-2.8: Minor issues, acceptable with polish
- 2.8-3.0: Ready for use
```

### Score Aggregation Across Personas

When multiple personas evaluate the same product:

1. Calculate individual persona scores
2. Weight by product type relevance (see personas.md)
3. Flag any persona giving score < 1.5 (critical concern)
4. Average remaining scores
5. Note consensus level for each dimension

### Priority Assignment from Scores

| Score Range | Priority | Action |
|-------------|----------|--------|
| < 1.0 | P0 | Block release until fixed |
| 1.0-1.5 | P1 | Fix before next release |
| 1.5-2.0 | P2 | Address in coming sprint |
| 2.0-2.5 | P3 | Backlog improvement |
| 2.5+ | - | No action required |
